{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"root\",\n",
    "  passwd=\"phpipamadmin\",\n",
    "  database=\"assetdb\"\n",
    ")\n",
    "\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"SHOW TABLES\")\n",
    "for x in mycursor:\n",
    "    print(x)\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"CREATE TABLE assetdb_main (srcaddr INT UNSIGNED, srcport MEDIUMINT UNSIGNED, first BIGINT UNSIGNED, last BIGINT UNSIGNED, protocol TINYINT UNSIGNED, flows SMALLINT UNSIGNED, packets MEDIUMINT UNSIGNED, bytes INT UNSIGNED, PRIMARY KEY(`srcaddr`)) \\\n",
    "ENGINE=InnoDB DEFAULT CHARSET=utf8 PARTITION BY HASH(srcaddr) partitions 64;\")\n",
    "\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130706433\n",
      "127.0.0.1\n"
     ]
    }
   ],
   "source": [
    "import socket  \n",
    "import struct  \n",
    "  \n",
    "\n",
    "ip = '127.0.0.1'  \n",
    "int_ip = struct.unpack('!I', socket.inet_aton(ip))[0]  \n",
    "print(int_ip)  \n",
    "str_ip = socket.inet_ntoa(struct.pack('!I', int_ip))  \n",
    "print(str_ip) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def protocol_to_number(protocol):\n",
    "    if protocol == 'TCP':\n",
    "        num = 1\n",
    "    elif protocol=='UDP':\n",
    "        num = 2\n",
    "    elif protocol == 'ssh':\n",
    "        num = 3\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20200528140758.json\n",
      "20200528141325.json\n",
      "20200528141851.json\n",
      "20200528142416.json\n",
      "20200528142940.json\n",
      "20200528143504.json\n",
      "20200528144029.json\n",
      "20200528144554.json\n",
      "20200528145119.json\n",
      "20200528145643.json\n",
      "20200528150208.json\n",
      "20200528150732.json\n",
      "20200528151257.json\n",
      "20200528151821.json\n",
      "20200528152346.json\n",
      "20200528152910.json\n",
      "20200528153435.json\n",
      "20200528153959.json\n",
      "20200528154524.json\n",
      "20200528155048.json\n",
      "20200528155613.json\n",
      "20200528160137.json\n",
      "20200528160702.json\n",
      "20200528161228.json\n",
      "20200528161752.json\n",
      "20200528162317.json\n",
      "20200528162841.json\n",
      "20200528163405.json\n",
      "20200528163930.json\n",
      "20200528164454.json\n",
      "20200528165019.json\n",
      "20200528165543.json\n",
      "20200528170107.json\n",
      "20200528170632.json\n",
      "20200528171156.json\n",
      "20200528171721.json\n",
      "20200528172246.json\n",
      "20200528172810.json\n",
      "20200528173335.json\n",
      "20200528173859.json\n",
      "20200528174424.json\n",
      "20200528174948.json\n",
      "20200528175513.json\n",
      "20200528180037.json\n",
      "20200528180602.json\n",
      "20200528181126.json\n",
      "20200528181650.json\n",
      "20200528182215.json\n",
      "20200528182740.json\n",
      "20200528183304.json\n",
      "20200528183829.json\n",
      "20200528184353.json\n",
      "20200528184917.json\n",
      "20200528185442.json\n",
      "20200528190006.json\n",
      "20200528190530.json\n",
      "20200528191055.json\n",
      "20200528191619.json\n",
      "20200528192143.json\n",
      "20200528192708.json\n",
      "20200528193232.json\n",
      "20200528193757.json\n",
      "20200528194321.json\n",
      "20200528194845.json\n",
      "20200528195410.json\n",
      "20200528195934.json\n",
      "20200528200458.json\n",
      "20200528201023.json\n",
      "20200528201547.json\n",
      "20200528202112.json\n",
      "20200528202636.json\n",
      "20200528203201.json\n",
      "20200528203725.json\n",
      "20200528204250.json\n",
      "20200528204814.json\n",
      "20200528205338.json\n",
      "20200528205903.json\n",
      "20200528210427.json\n",
      "20200528210951.json\n",
      "20200528211516.json\n",
      "20200528212040.json\n",
      "20200528212604.json\n",
      "20200528213129.json\n",
      "20200528213653.json\n",
      "20200528214217.json\n",
      "20200528214742.json\n",
      "20200528215306.json\n",
      "20200528215830.json\n",
      "20200528220354.json\n",
      "20200528220919.json\n",
      "20200528221443.json\n",
      "20200528222007.json\n",
      "20200528222532.json\n",
      "20200528223056.json\n",
      "20200528223620.json\n",
      "20200528224144.json\n",
      "20200528224709.json\n",
      "20200528225233.json\n",
      "20200528225758.json\n",
      "20200528230322.json\n",
      "20200528230846.json\n",
      "20200528231411.json\n",
      "20200528231935.json\n",
      "20200528232500.json\n",
      "20200528233025.json\n",
      "20200528233549.json\n",
      "20200528234113.json\n",
      "20200528234638.json\n",
      "20200528235202.json\n",
      "20200528235727.json\n",
      "20200529000251.json\n",
      "20200529000815.json\n",
      "20200529001340.json\n",
      "20200529001904.json\n",
      "20200529002428.json\n",
      "20200529002953.json\n",
      "20200529003517.json\n",
      "20200529004042.json\n",
      "20200529004606.json\n",
      "20200529005131.json\n",
      "20200529005655.json\n",
      "20200529010219.json\n",
      "20200529010744.json\n",
      "20200529011308.json\n",
      "20200529011832.json\n",
      "20200529012357.json\n",
      "20200529012921.json\n",
      "20200529013445.json\n",
      "20200529014010.json\n",
      "20200529014534.json\n",
      "20200529015058.json\n",
      "20200529015622.json\n",
      "20200529020147.json\n",
      "20200529020711.json\n",
      "20200529021237.json\n",
      "20200529021801.json\n",
      "20200529022325.json\n",
      "20200529022850.json\n",
      "20200529023414.json\n",
      "20200529023938.json\n",
      "20200529024503.json\n",
      "20200529025027.json\n",
      "20200529025551.json\n",
      "20200529030116.json\n",
      "20200529030640.json\n",
      "20200529031205.json\n",
      "20200529031729.json\n",
      "20200529032256.json\n",
      "20200529032823.json\n",
      "20200529033349.json\n",
      "20200529033918.json\n",
      "20200529034444.json\n",
      "20200529035008.json\n",
      "20200529035533.json\n",
      "20200529040057.json\n",
      "20200529040622.json\n",
      "20200529041147.json\n",
      "20200529041711.json\n",
      "20200529042236.json\n",
      "20200529042800.json\n",
      "20200529043325.json\n",
      "20200529043849.json\n",
      "20200529044414.json\n",
      "20200529044939.json\n",
      "20200529045503.json\n",
      "20200529050027.json\n",
      "20200529050552.json\n",
      "20200529051117.json\n",
      "20200529051641.json\n",
      "20200529052206.json\n",
      "20200529052730.json\n",
      "20200529053255.json\n",
      "20200529053819.json\n",
      "20200529054344.json\n",
      "20200529054908.json\n",
      "20200529055433.json\n",
      "20200529055958.json\n",
      "20200529060522.json\n",
      "20200529061047.json\n",
      "20200529061611.json\n",
      "20200529062136.json\n",
      "20200529062700.json\n",
      "20200529063225.json\n",
      "20200529063749.json\n",
      "20200529064314.json\n",
      "20200529064838.json\n",
      "20200529065403.json\n",
      "20200529065927.json\n",
      "20200529070452.json\n",
      "20200529071016.json\n",
      "20200529071540.json\n",
      "20200529072105.json\n",
      "20200529072629.json\n",
      "20200529073154.json\n",
      "20200529073718.json\n",
      "20200529074242.json\n",
      "20200529074807.json\n",
      "20200529075331.json\n",
      "20200529075855.json\n",
      "20200529080420.json\n",
      "20200529080944.json\n",
      "20200529081508.json\n",
      "20200529082033.json\n",
      "20200529082557.json\n",
      "20200529083122.json\n",
      "20200529083646.json\n",
      "20200529084210.json\n",
      "20200529084735.json\n",
      "20200529085259.json\n",
      "20200529085824.json\n",
      "20200529090348.json\n",
      "20200529090913.json\n",
      "20200529091437.json\n",
      "20200529092001.json\n",
      "20200529092526.json\n",
      "20200529093050.json\n",
      "20200529093614.json\n",
      "20200529094139.json\n",
      "20200529094703.json\n",
      "20200529095228.json\n",
      "20200529095752.json\n",
      "20200529100317.json\n",
      "20200529100841.json\n",
      "20200529101406.json\n",
      "20200529101930.json\n",
      "20200529102454.json\n",
      "20200529103019.json\n",
      "20200529103543.json\n",
      "20200528140758.json\n",
      "20200528141325.json\n",
      "20200528141851.json\n",
      "20200528142416.json\n",
      "20200528142940.json\n",
      "20200528143504.json\n",
      "20200528144029.json\n",
      "20200528144554.json\n",
      "20200528145119.json\n",
      "20200528145643.json\n",
      "20200528150208.json\n",
      "20200528150732.json\n",
      "20200528151257.json\n",
      "20200528151821.json\n",
      "20200528152346.json\n",
      "20200528152910.json\n",
      "20200528153435.json\n",
      "20200528153959.json\n",
      "20200528154524.json\n",
      "20200528155048.json\n",
      "20200528155613.json\n",
      "20200528160137.json\n",
      "20200528160702.json\n",
      "20200528161228.json\n",
      "20200528161752.json\n",
      "20200528162317.json\n",
      "20200528162841.json\n",
      "20200528163405.json\n",
      "20200528163930.json\n",
      "20200528164454.json\n",
      "20200528165019.json\n",
      "20200528165543.json\n",
      "20200528170107.json\n",
      "20200528170632.json\n",
      "20200528171156.json\n",
      "20200528171721.json\n",
      "20200528172246.json\n",
      "20200528172810.json\n",
      "20200528173335.json\n",
      "20200528173859.json\n",
      "20200528174424.json\n",
      "20200528174948.json\n",
      "20200528175513.json\n",
      "20200528180037.json\n",
      "20200528180602.json\n",
      "20200528181126.json\n",
      "20200528181650.json\n",
      "20200528182215.json\n",
      "20200528182740.json\n",
      "20200528183304.json\n",
      "20200528183829.json\n",
      "20200528184353.json\n",
      "20200528184917.json\n",
      "20200528185442.json\n",
      "20200528190006.json\n",
      "20200528190530.json\n",
      "20200528191055.json\n",
      "20200528191619.json\n",
      "20200528192143.json\n",
      "20200528192708.json\n",
      "20200528193232.json\n",
      "20200528193757.json\n",
      "20200528194321.json\n",
      "20200528194845.json\n",
      "20200528195410.json\n",
      "20200528195934.json\n",
      "20200528200458.json\n",
      "20200528201023.json\n",
      "20200528201547.json\n",
      "20200528202112.json\n",
      "20200528202636.json\n",
      "20200528203201.json\n",
      "20200528203725.json\n",
      "20200528204250.json\n",
      "20200528204814.json\n",
      "20200528205338.json\n",
      "20200528205903.json\n",
      "20200528210427.json\n",
      "20200528210951.json\n",
      "20200528211516.json\n",
      "20200528212040.json\n",
      "20200528212604.json\n",
      "20200528213129.json\n",
      "20200528213653.json\n",
      "20200528214217.json\n",
      "20200528214742.json\n",
      "20200528215306.json\n",
      "20200528215830.json\n",
      "20200528220354.json\n",
      "20200528220919.json\n",
      "20200528221443.json\n",
      "20200528222007.json\n",
      "20200528222532.json\n",
      "20200528223056.json\n",
      "20200528223620.json\n",
      "20200528224144.json\n",
      "20200528224709.json\n",
      "20200528225233.json\n",
      "20200528225758.json\n",
      "20200528230322.json\n",
      "20200528230846.json\n",
      "20200528231411.json\n",
      "20200528231935.json\n",
      "20200528232500.json\n",
      "20200528233025.json\n",
      "20200528233549.json\n",
      "20200528234113.json\n",
      "20200528234638.json\n",
      "20200528235202.json\n",
      "20200528235727.json\n",
      "20200529000251.json\n",
      "20200529000815.json\n",
      "20200529001340.json\n",
      "20200529001904.json\n",
      "20200529002428.json\n",
      "20200529002953.json\n",
      "20200529003517.json\n",
      "20200529004042.json\n",
      "20200529004606.json\n",
      "20200529005131.json\n",
      "20200529005655.json\n",
      "20200529010219.json\n",
      "20200529010744.json\n",
      "20200529011308.json\n",
      "20200529011832.json\n",
      "20200529012357.json\n",
      "20200529012921.json\n",
      "20200529013445.json\n",
      "20200529014010.json\n",
      "20200529014534.json\n",
      "20200529015058.json\n",
      "20200529015622.json\n",
      "20200529020147.json\n",
      "20200529020711.json\n",
      "20200529021237.json\n",
      "20200529021801.json\n",
      "20200529022325.json\n",
      "20200529022850.json\n",
      "20200529023414.json\n",
      "20200529023938.json\n",
      "20200529024503.json\n",
      "20200529025027.json\n",
      "20200529025551.json\n",
      "20200529030116.json\n",
      "20200529030640.json\n",
      "20200529031205.json\n",
      "20200529031729.json\n",
      "20200529032256.json\n",
      "20200529032823.json\n",
      "20200529033349.json\n",
      "20200529033918.json\n",
      "20200529034444.json\n",
      "20200529035008.json\n",
      "20200529035533.json\n",
      "20200529040057.json\n",
      "20200529040622.json\n",
      "20200529041147.json\n",
      "20200529041711.json\n",
      "20200529042236.json\n",
      "20200529042800.json\n",
      "20200529043325.json\n",
      "20200529043849.json\n",
      "20200529044414.json\n",
      "20200529044939.json\n",
      "20200529045503.json\n",
      "20200529050027.json\n",
      "20200529050552.json\n",
      "20200529051117.json\n",
      "20200529051641.json\n",
      "20200529052206.json\n",
      "20200529052730.json\n",
      "20200529053255.json\n",
      "20200529053819.json\n",
      "20200529054344.json\n",
      "20200529054908.json\n",
      "20200529055433.json\n",
      "20200529055958.json\n",
      "20200529060522.json\n",
      "20200529061047.json\n",
      "20200529061611.json\n",
      "20200529062136.json\n",
      "20200529062700.json\n",
      "20200529063225.json\n",
      "20200529063749.json\n",
      "20200529064314.json\n",
      "20200529064838.json\n",
      "20200529065403.json\n",
      "20200529065927.json\n",
      "20200529070452.json\n",
      "20200529071016.json\n",
      "20200529071540.json\n",
      "20200529072105.json\n",
      "20200529072629.json\n",
      "20200529073154.json\n",
      "20200529073718.json\n",
      "20200529074242.json\n",
      "20200529074807.json\n",
      "20200529075331.json\n",
      "20200529075855.json\n",
      "20200529080420.json\n",
      "20200529080944.json\n",
      "20200529081508.json\n",
      "20200529082033.json\n",
      "20200529082557.json\n",
      "20200529083122.json\n",
      "20200529083646.json\n",
      "20200529084210.json\n",
      "20200529084735.json\n",
      "20200529085259.json\n",
      "20200529085824.json\n",
      "20200529090348.json\n",
      "20200529090913.json\n",
      "20200529091437.json\n",
      "20200529092001.json\n",
      "20200529092526.json\n",
      "20200529093050.json\n",
      "20200529093614.json\n",
      "20200529094139.json\n",
      "20200529094703.json\n",
      "20200529095228.json\n",
      "20200529095752.json\n",
      "20200529100317.json\n",
      "20200529100841.json\n",
      "20200529101406.json\n",
      "20200529101930.json\n",
      "20200529102454.json\n",
      "20200529103019.json\n",
      "20200529103543.json\n",
      "['20200528140758.json', '20200528141325.json', '20200528141851.json', '20200528142416.json', '20200528142940.json', '20200528143504.json', '20200528144029.json', '20200528144554.json', '20200528145119.json', '20200528145643.json', '20200528150208.json', '20200528150732.json', '20200528151257.json', '20200528151821.json', '20200528152346.json', '20200528152910.json', '20200528153435.json', '20200528153959.json', '20200528154524.json', '20200528155048.json', '20200528155613.json', '20200528160137.json', '20200528160702.json', '20200528161228.json', '20200528161752.json', '20200528162317.json', '20200528162841.json', '20200528163405.json', '20200528163930.json', '20200528164454.json', '20200528165019.json', '20200528165543.json', '20200528170107.json', '20200528170632.json', '20200528171156.json', '20200528171721.json', '20200528172246.json', '20200528172810.json', '20200528173335.json', '20200528173859.json', '20200528174424.json', '20200528174948.json', '20200528175513.json', '20200528180037.json', '20200528180602.json', '20200528181126.json', '20200528181650.json', '20200528182215.json', '20200528182740.json', '20200528183304.json', '20200528183829.json', '20200528184353.json', '20200528184917.json', '20200528185442.json', '20200528190006.json', '20200528190530.json', '20200528191055.json', '20200528191619.json', '20200528192143.json', '20200528192708.json', '20200528193232.json', '20200528193757.json', '20200528194321.json', '20200528194845.json', '20200528195410.json', '20200528195934.json', '20200528200458.json', '20200528201023.json', '20200528201547.json', '20200528202112.json', '20200528202636.json', '20200528203201.json', '20200528203725.json', '20200528204250.json', '20200528204814.json', '20200528205338.json', '20200528205903.json', '20200528210427.json', '20200528210951.json', '20200528211516.json', '20200528212040.json', '20200528212604.json', '20200528213129.json', '20200528213653.json', '20200528214217.json', '20200528214742.json', '20200528215306.json', '20200528215830.json', '20200528220354.json', '20200528220919.json', '20200528221443.json', '20200528222007.json', '20200528222532.json', '20200528223056.json', '20200528223620.json', '20200528224144.json', '20200528224709.json', '20200528225233.json', '20200528225758.json', '20200528230322.json', '20200528230846.json', '20200528231411.json', '20200528231935.json', '20200528232500.json', '20200528233025.json', '20200528233549.json', '20200528234113.json', '20200528234638.json', '20200528235202.json', '20200528235727.json', '20200529000251.json', '20200529000815.json', '20200529001340.json', '20200529001904.json', '20200529002428.json', '20200529002953.json', '20200529003517.json', '20200529004042.json', '20200529004606.json', '20200529005131.json', '20200529005655.json', '20200529010219.json', '20200529010744.json', '20200529011308.json', '20200529011832.json', '20200529012357.json', '20200529012921.json', '20200529013445.json', '20200529014010.json', '20200529014534.json', '20200529015058.json', '20200529015622.json', '20200529020147.json', '20200529020711.json', '20200529021237.json', '20200529021801.json', '20200529022325.json', '20200529022850.json', '20200529023414.json', '20200529023938.json', '20200529024503.json', '20200529025027.json', '20200529025551.json', '20200529030116.json', '20200529030640.json', '20200529031205.json', '20200529031729.json', '20200529032256.json', '20200529032823.json', '20200529033349.json', '20200529033918.json', '20200529034444.json', '20200529035008.json', '20200529035533.json', '20200529040057.json', '20200529040622.json', '20200529041147.json', '20200529041711.json', '20200529042236.json', '20200529042800.json', '20200529043325.json', '20200529043849.json', '20200529044414.json', '20200529044939.json', '20200529045503.json', '20200529050027.json', '20200529050552.json', '20200529051117.json', '20200529051641.json', '20200529052206.json', '20200529052730.json', '20200529053255.json', '20200529053819.json', '20200529054344.json', '20200529054908.json', '20200529055433.json', '20200529055958.json', '20200529060522.json', '20200529061047.json', '20200529061611.json', '20200529062136.json', '20200529062700.json', '20200529063225.json', '20200529063749.json', '20200529064314.json', '20200529064838.json', '20200529065403.json', '20200529065927.json', '20200529070452.json', '20200529071016.json', '20200529071540.json', '20200529072105.json', '20200529072629.json', '20200529073154.json', '20200529073718.json', '20200529074242.json', '20200529074807.json', '20200529075331.json', '20200529075855.json', '20200529080420.json', '20200529080944.json', '20200529081508.json', '20200529082033.json', '20200529082557.json', '20200529083122.json', '20200529083646.json', '20200529084210.json', '20200529084735.json', '20200529085259.json', '20200529085824.json', '20200529090348.json', '20200529090913.json', '20200529091437.json', '20200529092001.json', '20200529092526.json', '20200529093050.json', '20200529093614.json', '20200529094139.json', '20200529094703.json', '20200529095228.json', '20200529095752.json', '20200529100317.json', '20200529100841.json', '20200529101406.json', '20200529101930.json', '20200529102454.json', '20200529103019.json', '20200529103543.json']\n"
     ]
    }
   ],
   "source": [
    "# Python read all files from a directory in order\n",
    "import os\n",
    "\n",
    "f = open(\"./data/netflow_name.txt\", 'w')\n",
    "path = \"./data/netflow/\"\n",
    "files = os.listdir(path)\n",
    "files.sort()\n",
    "\n",
    "s = []\n",
    "\n",
    "for file_name in files:\n",
    "    if not os.path.isdir(path + file_name):\n",
    "        f_name = str(file_name)\n",
    "        print(f_name)\n",
    "        s.append(f_name)\n",
    "        f.write(f_name + '\\n')\n",
    "for i in s:\n",
    "    print(i)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb in ./my_env/lib/python3.6/site-packages (5.3.0)\n",
      "Requirement already satisfied: pytz in ./my_env/lib/python3.6/site-packages (from influxdb) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.0 in ./my_env/lib/python3.6/site-packages (from influxdb) (2.8.1)\n",
      "Requirement already satisfied: six>=1.10.0 in ./my_env/lib/python3.6/site-packages (from influxdb) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.17.0 in ./my_env/lib/python3.6/site-packages (from influxdb) (2.23.0)\n",
      "Requirement already satisfied: msgpack==0.6.1 in ./my_env/lib/python3.6/site-packages (from influxdb) (0.6.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./my_env/lib/python3.6/site-packages (from requests>=2.17.0->influxdb) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./my_env/lib/python3.6/site-packages (from requests>=2.17.0->influxdb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./my_env/lib/python3.6/site-packages (from requests>=2.17.0->influxdb) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./my_env/lib/python3.6/site-packages (from requests>=2.17.0->influxdb) (2020.4.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install influxdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from influxdb import InfluxDBClient\n",
    "client = InfluxDBClient('localhost', 8086, 'root', '0318', 'assetdb_ts') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': '_internal'}, {'name': 'assetdb_ts'}]\n",
      "[{'name': '_internal'}, {'name': 'assetdb_ts'}]\n",
      "[{'name': '_internal'}]\n"
     ]
    }
   ],
   "source": [
    "print(client.get_list_database()) # 显示所有数据库名称\n",
    "client.create_database('assetdb_ts') # 创建数据库\n",
    "print(client.get_list_database()) # 显示所有数据库名称\n",
    "client.drop_database('assetdb_ts') # 删除数据库\n",
    "print(client.get_list_database()) # 显示所有数据库名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': '_internal'}, {'name': 'assetdb_ts'}]\n"
     ]
    }
   ],
   "source": [
    "client.create_database('assetdb_ts') # 创建数据库\n",
    "print(client.get_list_database()) # 显示所有数据库名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = InfluxDBClient('localhost', 8086, 'root', '0318', 'assetdb_ts') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_body = [\n",
    "    {\n",
    "        \"measurement\": \"time_series\",\n",
    "        \"tags\": {\n",
    "            \"ip\": \"10.10.10.10\"\n",
    "        },\n",
    "        #\"time\": \"2017-03-12T22:00:00Z\",\n",
    "        \"fields\": {\n",
    "            \"port\": 80,\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "client.write_points(json_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/test data/' + 'test_data.json') as record:\n",
    "        new_record = json.load(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: ResultSet({'('time_series', None)': [{'time': '2020-06-28T17:34:23.157384Z', 'ip': '10.10.10.10', 'port': 80}]})\n"
     ]
    }
   ],
   "source": [
    "result = client.query('select * from time_series;')    \n",
    "print(\"Result: {0}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create pandas DataFrame\n",
      "                      0\n",
      "2014-11-16 00:00:00   0\n",
      "2014-11-16 01:00:00   1\n",
      "2014-11-16 02:00:00   2\n",
      "2014-11-16 03:00:00   3\n",
      "2014-11-16 04:00:00   4\n",
      "2014-11-16 05:00:00   5\n",
      "2014-11-16 06:00:00   6\n",
      "2014-11-16 07:00:00   7\n",
      "2014-11-16 08:00:00   8\n",
      "2014-11-16 09:00:00   9\n",
      "2014-11-16 10:00:00  10\n",
      "2014-11-16 11:00:00  11\n",
      "2014-11-16 12:00:00  12\n",
      "2014-11-16 13:00:00  13\n",
      "2014-11-16 14:00:00  14\n",
      "2014-11-16 15:00:00  15\n",
      "2014-11-16 16:00:00  16\n",
      "2014-11-16 17:00:00  17\n",
      "2014-11-16 18:00:00  18\n",
      "2014-11-16 19:00:00  19\n",
      "2014-11-16 20:00:00  20\n",
      "2014-11-16 21:00:00  21\n",
      "2014-11-16 22:00:00  22\n",
      "2014-11-16 23:00:00  23\n",
      "2014-11-17 00:00:00  24\n",
      "2014-11-17 01:00:00  25\n",
      "2014-11-17 02:00:00  26\n",
      "2014-11-17 03:00:00  27\n",
      "2014-11-17 04:00:00  28\n",
      "2014-11-17 05:00:00  29\n",
      "Create database: assetdb_ts\n",
      "Write DataFrame\n",
      "Read DataFrame\n",
      "Result: defaultdict(<class 'list'>, {'demo':                                    srcaddr  srcport\n",
      "2020-05-28 14:07:31+00:00   125.202.46.124    10110\n",
      "2020-05-28 14:07:31+00:00  184.105.195.183    38885\n",
      "2020-05-28 14:07:31+00:00   57.216.112.001    63975})\n",
      "Delete database: assetdb_ts\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Tutorial for using pandas and the InfluxDB client.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from influxdb import DataFrameClient\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Instantiate the connection to the InfluxDB client.\"\"\"\n",
    "    user = 'root'\n",
    "    password = '0318'\n",
    "    dbname = 'assetdb_ts'\n",
    "    protocol = 'line'\n",
    "\n",
    "    client = DataFrameClient('localhost', 8086, user, password, dbname)\n",
    "\n",
    "    print(\"Create pandas DataFrame\")\n",
    "    df = pd.DataFrame(data=list(range(30)),\n",
    "                      index=pd.date_range(start='2014-11-16',\n",
    "                                          periods=30, freq='H'), columns=['0'])\n",
    "    print(df)\n",
    "    with open('data/test data/' + 'test_data.json') as record:\n",
    "        new_record = json.load(record)\n",
    "\n",
    "        new_record = pd.DataFrame(data=new_record,                       \n",
    "                                  columns=['srcaddr','srcport','First'])\n",
    "        new_record['First'] = pd.to_datetime(new_record['First'], format='%Y%m%d%H%M%S')\n",
    "        new_record.set_index('First', inplace=True)\n",
    "\n",
    "        print(\"Create database: \" + dbname)\n",
    "        client.create_database(dbname)\n",
    "\n",
    "        print(\"Write DataFrame\")\n",
    "        #tags = { \"srcaddr\": new_record[[\"srcaddr\"]],  \"srcport\": new_record[[\"srcport\"]]}\n",
    "        #client.write_points(new_record, 'demo', tags = tags, protocol=\"json\")\n",
    "        client.write_points(new_record, 'demo', tag_columns=['srcaddr'], protocol=protocol)\n",
    "\n",
    "        print(\"Read DataFrame\")\n",
    "        result = client.query(\"select * from demo\")\n",
    "        print(\"Result: {0}\".format(result))\n",
    "\n",
    "        print(\"Delete database: \" + dbname)\n",
    "        client.drop_database(dbname)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse the args from main.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='example code to play with InfluxDB')\n",
    "    parser.add_argument('--host', type=str, required=False,\n",
    "                        default='localhost',\n",
    "                        help='hostname of InfluxDB http API')\n",
    "    parser.add_argument('--port', type=int, required=False, default=8086,\n",
    "                        help='port of InfluxDB http API')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'srcaddr': '57.216.112.001', 'srcport': 63975, 'First': 20200528140731, 'Last': 20200528140931, 'protocol': 'UDP', 'flows': 18, 'packets': 295, 'bytes': 482341}, {'srcaddr': '184.105.195.183', 'srcport': 38885, 'First': 20200528140731, 'Last': 20200528142533, 'protocol': 'TCP', 'flows': 3, 'packets': 112, 'bytes': 215847}, {'srcaddr': '125.202.46.124', 'srcport': 10110, 'First': 20200528140731, 'Last': 20200528142534, 'protocol': 'UDP', 'flows': 1, 'packets': 243, 'bytes': 115125}]\n",
      "Create pandas DataFrame\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (3, 2), indices imply (1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mblocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mform_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1671\u001b[0;31m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBlockManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1672\u001b[0m         \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, blocks, axes, do_integrity_check)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdo_integrity_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_verify_integrity\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_verify_integrity\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mmgr_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtot_items\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (3, 2), indices imply (1, 2)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-e4e305e372a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-106-e4e305e372a7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         df = pd.DataFrame(new_record,\n\u001b[1;32m     28\u001b[0m                           \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'First'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                           columns=['srcaddr','srcport'])\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    484\u001b[0m                             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mibase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcreate_block_manager_from_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mcreate_block_manager_from_arrays\u001b[0;34m(arrays, names, axes)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         \u001b[0mconstruction_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/my_env/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mconstruction_error\u001b[0;34m(tot_items, block_shape, axes, e)\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mblock_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Empty data passed with indices specified.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of passed values is {passed}, indices imply {implied}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (3, 2), indices imply (1, 2)"
     ]
    }
   ],
   "source": [
    "\"\"\"Tutorial for using pandas and the InfluxDB client.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from influxdb import DataFrameClient\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Instantiate the connection to the InfluxDB client.\"\"\"\n",
    "    user = 'root'\n",
    "    password = '0318'\n",
    "    dbname = 'assetdb_ts'\n",
    "    protocol = 'line'\n",
    "\n",
    "    client = DataFrameClient('localhost', 8086, user, password, dbname)\n",
    "    with open('data/test data/' + 'test_data.json') as record:\n",
    "        new_record = json.load(record)\n",
    "        print(new_record)\n",
    "\n",
    "        print(\"Create pandas DataFrame\")\n",
    "        df = pd.DataFrame(new_record,\n",
    "                          columns=['srcaddr','srcport','First'])\n",
    "            df['First'] = pd.to_datetime(df['First'], format='%Y%m%d%H%M%S')\n",
    "        \n",
    "        df = pd.DataFrame(new_record,\n",
    "                          index=pd.to_datetime(new_record['First'], format='%Y%m%d%H%M%S'), \n",
    "                          columns=['srcaddr','srcport','First'])\n",
    "\n",
    "        print(df)\n",
    "        # df.set_index('First', inplace=True)\n",
    "        \n",
    "        \n",
    "        print(df)\n",
    "        print(\"Create database: \" + dbname)\n",
    "        client.create_database(dbname)\n",
    "\n",
    "        print(\"Write DataFrame\")\n",
    "        client.write_points(df, 'demo', protocol=protocol)\n",
    "\n",
    "        print(\"Write DataFrame with Tags\")\n",
    "        client.write_points(df, 'demo',\n",
    "                            {'k1': 'v1', 'k2': 'v2'}, protocol=protocol)\n",
    "\n",
    "        print(\"Read DataFrame\")\n",
    "        result = client.query(\"select * from demo\")\n",
    "        print(\"Result: {0}\".format(result))\n",
    "\n",
    "        print(\"Delete database: \" + dbname)\n",
    "        client.drop_database(dbname)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse the args from main.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='example code to play with InfluxDB')\n",
    "    parser.add_argument('--host', type=str, required=False,\n",
    "                        default='localhost',\n",
    "                        help='hostname of InfluxDB http API')\n",
    "    parser.add_argument('--port', type=int, required=False, default=8086,\n",
    "                        help='port of InfluxDB http API')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6420990403015211'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "tupTime = time.localtime(20200528140731)\n",
    "time.strftime(\"%Y%m%d%H%M%S\", tupTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create pandas DataFrame\n",
      "                      0\n",
      "2014-11-16 00:00:00   0\n",
      "2014-11-16 01:00:00   1\n",
      "2014-11-16 02:00:00   2\n",
      "2014-11-16 03:00:00   3\n",
      "2014-11-16 04:00:00   4\n",
      "2014-11-16 05:00:00   5\n",
      "2014-11-16 06:00:00   6\n",
      "2014-11-16 07:00:00   7\n",
      "2014-11-16 08:00:00   8\n",
      "2014-11-16 09:00:00   9\n",
      "2014-11-16 10:00:00  10\n",
      "2014-11-16 11:00:00  11\n",
      "2014-11-16 12:00:00  12\n",
      "2014-11-16 13:00:00  13\n",
      "2014-11-16 14:00:00  14\n",
      "2014-11-16 15:00:00  15\n",
      "2014-11-16 16:00:00  16\n",
      "2014-11-16 17:00:00  17\n",
      "2014-11-16 18:00:00  18\n",
      "2014-11-16 19:00:00  19\n",
      "2014-11-16 20:00:00  20\n",
      "2014-11-16 21:00:00  21\n",
      "2014-11-16 22:00:00  22\n",
      "2014-11-16 23:00:00  23\n",
      "2014-11-17 00:00:00  24\n",
      "2014-11-17 01:00:00  25\n",
      "2014-11-17 02:00:00  26\n",
      "2014-11-17 03:00:00  27\n",
      "2014-11-17 04:00:00  28\n",
      "2014-11-17 05:00:00  29\n",
      "Create database: assetdb_ts\n",
      "Write DataFrame\n",
      "Write DataFrame with Tags\n",
      "Read DataFrame\n",
      "Result: defaultdict(<class 'list'>, {'demo':                             0    k1    k2\n",
      "2014-11-16 00:00:00+00:00   0  None  None\n",
      "2014-11-16 00:00:00+00:00   0    v1    v2\n",
      "2014-11-16 01:00:00+00:00   1  None  None\n",
      "2014-11-16 01:00:00+00:00   1    v1    v2\n",
      "2014-11-16 02:00:00+00:00   2  None  None\n",
      "2014-11-16 02:00:00+00:00   2    v1    v2\n",
      "2014-11-16 03:00:00+00:00   3  None  None\n",
      "2014-11-16 03:00:00+00:00   3    v1    v2\n",
      "2014-11-16 04:00:00+00:00   4  None  None\n",
      "2014-11-16 04:00:00+00:00   4    v1    v2\n",
      "2014-11-16 05:00:00+00:00   5  None  None\n",
      "2014-11-16 05:00:00+00:00   5    v1    v2\n",
      "2014-11-16 06:00:00+00:00   6  None  None\n",
      "2014-11-16 06:00:00+00:00   6    v1    v2\n",
      "2014-11-16 07:00:00+00:00   7  None  None\n",
      "2014-11-16 07:00:00+00:00   7    v1    v2\n",
      "2014-11-16 08:00:00+00:00   8  None  None\n",
      "2014-11-16 08:00:00+00:00   8    v1    v2\n",
      "2014-11-16 09:00:00+00:00   9  None  None\n",
      "2014-11-16 09:00:00+00:00   9    v1    v2\n",
      "2014-11-16 10:00:00+00:00  10  None  None\n",
      "2014-11-16 10:00:00+00:00  10    v1    v2\n",
      "2014-11-16 11:00:00+00:00  11  None  None\n",
      "2014-11-16 11:00:00+00:00  11    v1    v2\n",
      "2014-11-16 12:00:00+00:00  12  None  None\n",
      "2014-11-16 12:00:00+00:00  12    v1    v2\n",
      "2014-11-16 13:00:00+00:00  13  None  None\n",
      "2014-11-16 13:00:00+00:00  13    v1    v2\n",
      "2014-11-16 14:00:00+00:00  14  None  None\n",
      "2014-11-16 14:00:00+00:00  14    v1    v2\n",
      "2014-11-16 15:00:00+00:00  15  None  None\n",
      "2014-11-16 15:00:00+00:00  15    v1    v2\n",
      "2014-11-16 16:00:00+00:00  16  None  None\n",
      "2014-11-16 16:00:00+00:00  16    v1    v2\n",
      "2014-11-16 17:00:00+00:00  17  None  None\n",
      "2014-11-16 17:00:00+00:00  17    v1    v2\n",
      "2014-11-16 18:00:00+00:00  18  None  None\n",
      "2014-11-16 18:00:00+00:00  18    v1    v2\n",
      "2014-11-16 19:00:00+00:00  19  None  None\n",
      "2014-11-16 19:00:00+00:00  19    v1    v2\n",
      "2014-11-16 20:00:00+00:00  20  None  None\n",
      "2014-11-16 20:00:00+00:00  20    v1    v2\n",
      "2014-11-16 21:00:00+00:00  21  None  None\n",
      "2014-11-16 21:00:00+00:00  21    v1    v2\n",
      "2014-11-16 22:00:00+00:00  22  None  None\n",
      "2014-11-16 22:00:00+00:00  22    v1    v2\n",
      "2014-11-16 23:00:00+00:00  23  None  None\n",
      "2014-11-16 23:00:00+00:00  23    v1    v2\n",
      "2014-11-17 00:00:00+00:00  24  None  None\n",
      "2014-11-17 00:00:00+00:00  24    v1    v2\n",
      "2014-11-17 01:00:00+00:00  25  None  None\n",
      "2014-11-17 01:00:00+00:00  25    v1    v2\n",
      "2014-11-17 02:00:00+00:00  26  None  None\n",
      "2014-11-17 02:00:00+00:00  26    v1    v2\n",
      "2014-11-17 03:00:00+00:00  27  None  None\n",
      "2014-11-17 03:00:00+00:00  27    v1    v2\n",
      "2014-11-17 04:00:00+00:00  28  None  None\n",
      "2014-11-17 04:00:00+00:00  28    v1    v2\n",
      "2014-11-17 05:00:00+00:00  29  None  None\n",
      "2014-11-17 05:00:00+00:00  29    v1    v2})\n",
      "Delete database: assetdb_ts\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Tutorial for using pandas and the InfluxDB client.\"\"\"\n",
    "\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from influxdb import DataFrameClient\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Instantiate the connection to the InfluxDB client.\"\"\"\n",
    "    user = 'root'\n",
    "    password = '0318'\n",
    "    dbname = 'assetdb_ts'\n",
    "    protocol = 'line'\n",
    "\n",
    "    client = DataFrameClient('localhost', 8086, user, password, dbname)\n",
    "\n",
    "\n",
    "    print(\"Create pandas DataFrame\")\n",
    "    df = pd.DataFrame(data=list(range(30)),\n",
    "                      index=pd.date_range(start='2014-11-16',\n",
    "                                          periods=30, freq='H'), columns=['0'])\n",
    "    print(df)\n",
    "    print(\"Create database: \" + dbname)\n",
    "    client.create_database(dbname)\n",
    "\n",
    "    print(\"Write DataFrame\")\n",
    "    client.write_points(df, 'demo', protocol=protocol)\n",
    "\n",
    "    print(\"Write DataFrame with Tags\")\n",
    "    client.write_points(df, 'demo',\n",
    "                        {'k1': 'v1', 'k2': 'v2'}, protocol=protocol)\n",
    "\n",
    "    print(\"Read DataFrame\")\n",
    "    result = client.query(\"select * from demo\")\n",
    "    print(\"Result: {0}\".format(result))\n",
    "\n",
    "    print(\"Delete database: \" + dbname)\n",
    "    client.drop_database(dbname)\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse the args from main.\"\"\"\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='example code to play with InfluxDB')\n",
    "    parser.add_argument('--host', type=str, required=False,\n",
    "                        default='localhost',\n",
    "                        help='hostname of InfluxDB http API')\n",
    "    parser.add_argument('--port', type=int, required=False, default=8086,\n",
    "                        help='port of InfluxDB http API')\n",
    "    return parser.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "# update 1 X 1000000 records at a time\n",
    "# Use List to collect the time of each insert operation for every 1 million records\n",
    "# Insert thread pool configuration\n",
    "\n",
    "time_records = []\n",
    "time_records_opt = []\n",
    "\n",
    "for json_name in s:\n",
    "#    mydb.reconnect()\n",
    "    mycursor = mydb.cursor()\n",
    "    sql_update = \"INSERT INTO p2_netflow (srcaddr, srcport, first, last, protocol, flows, packets, bytes) VALUES (%s,%s,%s,%s,%s,%s,%s,%s) ON DUPLICATE KEY UPDATE `last` = VALUES(`last`), `flows`= VALUES(`flows`) + `flows`, `packets`= VALUES(`packets`) + `packets`, `bytes`= VALUES(`bytes`) + `bytes`\"\n",
    "\n",
    "    start_time = time.time()\n",
    "    flows = []\n",
    "    with open('data/netflow/' + json_name) as record:\n",
    "        new_record = json.load(record)\n",
    "        new_record.sort(key=lambda k: (k.get('srcaddr', 0)))\n",
    "        for flow in new_record:\n",
    "            srcaddr = struct.unpack('!I', socket.inet_aton(flow[\"srcaddr\"]))[0]\n",
    "            protocol = protocol_to_number(flow[\"protocol\"])\n",
    "            flow_one = (srcaddr, flow[\"srcport\"], flow[\"First\"], flow[\"Last\"], protocol, flow[\"flows\"], flow[\"packets\"], flow[\"bytes\"])\n",
    "            flows.append(flow_one)\n",
    "        mycursor.executemany(sql_update, flows)\n",
    "        print(mycursor.rowcount, \"records inserted successful。\")\n",
    "        mycursor.close()\n",
    "        mydb.commit()    # 数据表内容有更新，必须使用到该语句\n",
    "#       mydb.close()\n",
    "        end_time = time.time()\n",
    "        consume_time = end_time - start_time\n",
    "        time_records.append(consume_time)\n",
    "        print(consume_time) \n",
    "        consume_time = '{:0>2s}'.format(str(int(consume_time // 3600))) \\\n",
    "               + ':{:0>2s}'.format(str(int((consume_time // 60) % 60))) \\\n",
    "               + ':{:0>2s}'.format(str(int(consume_time % 60)))\n",
    "        time_records_opt.append(consume_time)\n",
    "        print(consume_time) \n",
    "        \n",
    "mydb.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
